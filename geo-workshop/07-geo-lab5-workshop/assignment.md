---
slug: geo-lab5-workshop
id: egxuiyqry1p4
type: challenge
title: 'Elastic Geo Lab 5: Ingest Pipelines [PLACEHOLDER]'
teaser: Learn about Elasticsearch ingest pipelines.
notes:
- type: text
  contents: Please be patient as we set up the the lab 5 challenge.
tabs:
- id: l7ktjr5kfe2p
  title: Kibana
  type: service
  hostname: kubernetes-vm
  path: /app/discover#/view/fb5396f0-4c2e-11ee-a369-9fe9cf70b370?_g=(filters:!(),refreshInterval:(pause:!t,value:60000),time:(from:now-2y,to:now))
  port: 30001
  custom_request_headers:
  - key: Content-Security-Policy
    value: 'script-src ''self''; worker-src blob: ''self''; style-src ''unsafe-inline''
      ''self'''
  custom_response_headers:
  - key: Content-Security-Policy
    value: 'script-src ''self''; worker-src blob: ''self''; style-src ''unsafe-inline''
      ''self'''
- id: 1e3b4sw1oy9c
  title: host
  type: terminal
  hostname: kubernetes-vm
difficulty: ""
timelimit: 600
enhanced_loading: null
---
In Lab 5,  you will practice aggregations and group the data and apply metric functions to each group.

ES|QL Processing Command: stats... by
===
<ins>Review</ins>: <code>stats... by</code> groups the rows of a table into buckets based on values of a given field/column or based on grouping generated by the auto_buckets function
One or more column aggregation function can be applied to rows of each bucket.

The following query uses the <code>stats</code> command to find the sum of bytes in the entire logs data set.
```
from kibana_sample_data_logs
| stats sum_bytes = sum(bytes)
```
You can add by to <code>stats</code> to group the data by a column before applying the metric. The following query finds the sum of bytes for each host in the logs data set.
```
from kibana_sample_data_logs
| stats sum_bytes = sum(bytes) by host
```

<ins>Question 1</ins>: Write an ES|QL query from the kibana_sample_data_flights data set that groups the flights data set by Carrier and finds the average FlightDelayMin.

<details>
	<summary><int>Answer</int></summary>
<code><pre>
from kibana_sample_data_flights
| stats avg_delay = avg(FlightDelayMin) by Carrier
</pre></code>
</details>

From the lecture, you can calculate more than one metric in a single query and you can also group the data more than once.

<ins>Question 2</ins>: Add to the previous ES|QL query to find the total FlightDelayMin in addition to the average, and to group the data by FlightDelayType in addition to Carrier. Sort the results by Carrier and the FlightDelayType.

<details>
	<summary><ins>Answer</ins></summary>
<code><pre>
from kibana_sample_data_flights
| keep Carrier, FlightDelayMin, FlightDelayType
| stats avg_delay = avg(FlightDelayMin), total_delay = sum(FlightDelayMin) by Carrier, FlightDelayType
| sort Carrier, FlightDelayType
</pre></code>
</details>

<ins>Question 3</ins>: Find the median and the median absolute deviation for the flights that had a Carrier Delay. Reference the in product documentation and find the special considerations about these two metrics that may be of concern.

<details>
	<summary><ins>Answer</ins></summary>
<code><pre>
from kibana_sample_data_flights
| keep Carrier, FlightDelayMin, FlightDelayType
| where FlightDelayType == "Carrier Delay"
| stats median = median(FlightDelayMin), median_abs_dev = median_absolute_deviation(FlightDelayMin)
</pre></code>
</details>

> [!NOTE]
> The median and median absolute deviation metrics are approximations. The median absolute deviation is based on a non-deterministic algorithm so you may get slightly different results using the same data. The median function is considered a special case of the percentile function.

<ins>Question 4</ins>:  Find the 0th, 50th, and 95th percentiles of the FlightDelayMin for those flights that had a Carrier Delay

<details>
	<summary><ins>Answer</ins></summary>
<code><pre>
from kibana_sample_data_flights
| keep Carrier, FlightDelayMin, FlightDelayType
| where FlightDelayType == "Carrier Delay"
| stats p0 = percentile(FlightDelayMin, 0), p50 = percentile(FlightDelayMin, 50), p95 = percentile(FlightDelayMin, 95)
</pre></code>
</details>

<ins>Question 5</ins>:  Find the number of distinct customers from the index kibana_sample_data_ecommerce. Remember from the lecture that this metric is also an approximation.

<details>
	<summary><ins>Answer</ins></summary>
<code><pre>
from kibana_sample_data_ecommerce
| keep customer_full_name
| stats distinct_customers = count_distinct(customer_full_name)
</pre></code>
</details>

<ins>Question 6</ins>:  To count the number of rows in a data set you must use count on a single-valued field without null values, this is because ES|QL currently doesn't have a count <code>(*)</code> aggregation function yet.  Find the number of ecommerce orders.

<details>
	<summary><ins>Answer</ins></summary>
<code><pre>
from kibana_sample_data_ecommerce
| keep order_id
| stats num_orders = count(order_id)
</pre></code>
</details>
*****SAMPLE QUERY DOESNT USE IT ABOVE QUERY*****
Every order has a single order_id you can use count on this column to find the total number of orders.

The auto_bucket function can create a grouping for a numeric or a date column. The following example creates a grouping for an age column corresponding to the range from 10 to 100 divided into 5 buckets.
```
age_buckets = auto_bucket(age, 5, 10, 100)
```
You can then use the buckets to create a histogram using <code>stats ... by</code>:
*****SAMPLE QUERY DOESNT USE IT ABOVE QUERY *****
```
  stats age_histogram = median(income) by age_buckets
```
<ins>Question 7</ins>:  Write an ES|QL query that will produce a histogram for flights delayed based on their distance from the index kibana_sample_data_flights. Use a range from 0 to 20000 miles and 20 maximum buckets. Use total flight delay as the metric.

<details>
	<summary><ins>Answer</ins></summary>
<code><pre>
from kibana_sample_data_flights
| where FlightDelay
| keep Carrier, FlightNum, DistanceMiles, FlightDelayMin
| eval distance_buckets = auto_bucket(DistanceMiles, 20, 0, 20000)
| stats delay = sum(FlightDelayMin) by distance_buckets, Carrier
| sort Carrier
| limit 1000
</pre></code>
</details>

<ins>Question 8</ins>: Write an ES|QL query that generates a date histogram for the kibana_sample_data_logs index. Use the sum of bytes as the metric and choose a suitable date range. Experiment with the maximum number of buckets and observe the actual number of buckets created by ES|QL.

<details>
	<summary><ins>Answer</ins></summary>
<code><pre>
from kibana_sample_data_logs
| keep @timestamp, bytes
| eval date_buckets = auto_bucket(@timestamp, 200, "2023-08-13T00:00:00.000Z", "2023-10-12T21:00:00.000Z")
| stats sum_bytes = sum(bytes) by date_buckets
| sort date_buckets asc
</pre></code>
</details>


<details>
	<summary><ins>Hint</ins></summary>
You can find the number of buckets by adding the following command.
<code><pre>
| stats num_buckets = count(date_buckets)
</pre></code>
</details>

Congratulations, you have completed Lab 5. Click the **Next** button to proceed to Lab 6.
